{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ee3d44",
   "metadata": {},
   "source": [
    "# GA & PSO Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Required Libraries ---\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon, ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, sys\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- Set Up Paths ---\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if ROOT_PATH not in sys.path:\n",
    "    sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "# --- Import Custom Libraries ---\n",
    "from pop.util.fine_tuning import get_results_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79130b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e929e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df = pd.read_csv(get_results_path(\"final_fine_tuning_results.csv\"))\n",
    "ga_sharpe = final_results_df[final_results_df[\"algorithm\"] == \"GA\"][\"sharpe_ratio\"]\n",
    "pso_sharpe = final_results_df[final_results_df[\"algorithm\"] == \"PSO\"][\"sharpe_ratio\"]\n",
    "\n",
    "t_stat, p_value = ttest_ind(ga_sharpe, pso_sharpe, equal_var=False)\n",
    "print(f\"T-test for Sharpe Ratio: t={t_stat:.3f}, p={p_value:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b09f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_results_df.groupby([\"algorithm\", \"quality\"])[[\"sharpe_ratio\", \"annual_return\", \"runtime\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e163c5c2",
   "metadata": {},
   "source": [
    "## Load GA & PSO Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Paths to results\n",
    "# GA_RESULTS_PATH = \"experiments/results/ga/\"\n",
    "# PSO_RESULTS_PATH = \"experiments/results/pso/\"\n",
    "\n",
    "# # Load results\n",
    "# ga_results = pd.read_csv(GA_RESULTS_PATH)\n",
    "# pso_results = pd.read_csv(PSO_RESULTS_PATH)\n",
    "\n",
    "# # Add algorithm labels\n",
    "# ga_results[\"algorithm\"] = \"GA\"\n",
    "# pso_results[\"algorithm\"] = \"PSO\"\n",
    "\n",
    "# # Combine results\n",
    "# combined_results = pd.concat([ga_results, pso_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440edd14",
   "metadata": {},
   "source": [
    "## Plot Boxplots for Fitness & Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot fitness boxplots\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.boxplot(x=\"num_companies\", y=\"sharpe_ratio\", hue=\"algorithm\", data=combined_results, palette={\"GA\": \"blue\", \"PSO\": \"orange\"})\n",
    "# plt.title(\"Fitness Comparison by Portfolio Size\")\n",
    "# plt.xlabel(\"Number of Assets\")\n",
    "# plt.ylabel(\"Sharpe Ratio\")\n",
    "# plt.legend(title=\"Algorithm\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot evaluations boxplots\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.boxplot(x=\"num_companies\", y=\"n_evaluations\", hue=\"algorithm\", data=combined_results, palette={\"GA\": \"blue\", \"PSO\": \"orange\"})\n",
    "# plt.title(\"Evaluations Comparison by Portfolio Size\")\n",
    "# plt.xlabel(\"Number of Assets\")\n",
    "# plt.ylabel(\"Number of Evaluations\")\n",
    "# plt.legend(title=\"Algorithm\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9756752",
   "metadata": {},
   "source": [
    "## Wilcoxon Signed-Rank Test for Pairwise Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c648df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.05\n",
    "\n",
    "# # Iterate over unique portfolio sizes\n",
    "# for num_companies in combined_results[\"num_companies\"].unique():\n",
    "#     print(f\"\\nPortfolio Size: {num_companies}\")\n",
    "\n",
    "#     # Filter results for the current portfolio size\n",
    "#     ga_data = combined_results[(combined_results[\"num_companies\"] == num_companies) & (combined_results[\"algorithm\"] == \"GA\")]\n",
    "#     pso_data = combined_results[(combined_results[\"num_companies\"] == num_companies) & (combined_results[\"algorithm\"] == \"PSO\")]\n",
    "\n",
    "#     # Perform Wilcoxon test for fitness\n",
    "#     stat, p_value = wilcoxon(ga_data[\"sharpe_ratio\"], pso_data[\"sharpe_ratio\"])\n",
    "#     print(f\"Fitness - GA Mean: {ga_data['sharpe_ratio'].mean():.4f}, PSO Mean: {pso_data['sharpe_ratio'].mean():.4f}\")\n",
    "#     print(\"The difference in fitness is statistically significant.\" if p_value < alpha else \"The difference in fitness is NOT statistically significant.\")\n",
    "\n",
    "#     # Perform Wilcoxon test for evaluations\n",
    "#     stat, p_value = wilcoxon(ga_data[\"n_evaluations\"], pso_data[\"n_evaluations\"])\n",
    "#     print(f\"Evaluations - GA Mean: {ga_data['n_evaluations'].mean():.4f}, PSO Mean: {pso_data['n_evaluations'].mean():.4f}\")\n",
    "#     print(\"The difference in evaluations is statistically significant.\" if p_value < alpha else \"The difference in evaluations is NOT statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abff3d",
   "metadata": {},
   "source": [
    "## Friedman Test for Overall Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232fd963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import friedmanchisquare\n",
    "\n",
    "# # Prepare data for Friedman test\n",
    "# fitness_data = [\n",
    "#     combined_results[(combined_results[\"num_companies\"] == num_companies) & (combined_results[\"algorithm\"] == \"GA\")][\"sharpe_ratio\"].values\n",
    "#     for num_companies in combined_results[\"num_companies\"].unique()\n",
    "# ] + [\n",
    "#     combined_results[(combined_results[\"num_companies\"] == num_companies) & (combined_results[\"algorithm\"] == \"PSO\")][\"sharpe_ratio\"].values\n",
    "#     for num_companies in combined_results[\"num_companies\"].unique()\n",
    "# ]\n",
    "\n",
    "# # Perform Friedman test for fitness\n",
    "# stat, p_value = friedmanchisquare(*fitness_data)\n",
    "# print(\"Friedman Test for Fitness\")\n",
    "# print(f\"Statistic: {stat:.4f}, P-Value: {p_value:.4f}\")\n",
    "# print(\"The difference in fitness across algorithms is statistically significant.\" if p_value < alpha else \"The difference in fitness across algorithms is NOT statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76a048",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec35da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "# Load the final aggregated results\n",
    "data = pd.read_csv(os.path.join(ROOT_PATH, \"experiments\",\"results\",\"final_fine_tuning_results.csv\"))\n",
    "\n",
    "# Set the alpha value for statistical tests\n",
    "alpha = 0.05\n",
    "\n",
    "# Statistical Tests\n",
    "def perform_statistical_tests(ga_data, pso_data, metric, description):\n",
    "    print(f\"\\n{description} - Statistical Tests\")\n",
    "    # Drop NaN values to avoid calculation issues\n",
    "    ga_data = ga_data[metric].dropna()\n",
    "    pso_data = pso_data[metric].dropna()\n",
    "\n",
    "    if ga_data.empty or pso_data.empty:\n",
    "        print(\"⚠️ One of the data sets is empty after removing NaN values. Skipping test.\")\n",
    "        return\n",
    "\n",
    "    print(f\"GA Mean: {ga_data.mean():.4f}, PSO Mean: {pso_data.mean():.4f}\")\n",
    "\n",
    "    # Wilcoxon test (non-parametric)\n",
    "    try:\n",
    "        stat, p_value = wilcoxon(ga_data, pso_data)\n",
    "        print(f\"Wilcoxon Test: Statistic={stat:.4f}, P-Value={p_value:.4f}\")\n",
    "        if p_value < alpha:\n",
    "            print(\"Difference is statistically significant.\")\n",
    "        else:\n",
    "            print(\"Difference is NOT statistically significant.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in Wilcoxon Test: {e}\")\n",
    "\n",
    "    # Paired t-Test (parametric)\n",
    "    try:\n",
    "        stat, p_value = ttest_rel(ga_data, pso_data)\n",
    "        print(f\"Paired t-Test: Statistic={stat:.4f}, P-Value={p_value:.4f}\")\n",
    "        if p_value < alpha:\n",
    "            print(\"Difference is statistically significant.\")\n",
    "        else:\n",
    "            print(\"Difference is NOT statistically significant.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in Paired t-Test: {e}\")\n",
    "\n",
    "# Perform tests for Best, Median, and Worst Configurations\n",
    "for quality in [\"best\", \"median\", \"worst\"]:\n",
    "    ga_data = data[(data[\"algorithm\"] == \"GA\") & (data[\"quality\"] == quality)]\n",
    "    pso_data = data[(data[\"algorithm\"] == \"PSO\") & (data[\"quality\"] == quality)]\n",
    "    perform_statistical_tests(ga_data, pso_data, \"sharpe_ratio\", f\"Sharpe Ratio ({quality})\")\n",
    "    perform_statistical_tests(ga_data, pso_data, \"annual_return\", f\"Annual Return ({quality})\")\n",
    "    perform_statistical_tests(ga_data, pso_data, \"runtime\", f\"Execution Time ({quality})\")\n",
    "\n",
    "# Visualization Functions\n",
    "def bar_plot(data, metric, title, ylabel):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(data=data, x=\"quality\", y=metric, hue=\"algorithm\", errorbar=None)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "def box_plot(data, metric, title, ylabel):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=data, x=\"algorithm\", y=metric, hue=\"quality\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "def scatter_plot(data, x_metric, y_metric, title, xlabel, ylabel):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=data, x=x_metric, y=y_metric, hue=\"algorithm\", style=\"quality\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "# Visualization: Sharpe Ratio Comparison (Best, Median, Worst)\n",
    "bar_plot(data, \"mean_sharpe\", \"Mean Sharpe Ratios (GA vs PSO)\", \"Mean Sharpe Ratio\")\n",
    "\n",
    "# Visualization: Return Distribution (Best, Median, Worst)\n",
    "box_plot(data, \"annual_return\", \"Annual Return Distributions (GA vs PSO)\", \"Annual Return\")\n",
    "\n",
    "# Visualization: Execution Time Comparison (Best, Median, Worst)\n",
    "bar_plot(data, \"runtime\", \"Execution Time (GA vs PSO)\", \"Runtime (seconds)\")\n",
    "\n",
    "# Visualization: Tradeoff Analysis (Sharpe Ratio vs. Time)\n",
    "scatter_plot(data, \"runtime\", \"sharpe_ratio\", \"Sharpe Ratio vs. Execution Time (GA vs PSO)\", \"Execution Time (seconds)\", \"Sharpe Ratio\")\n",
    "\n",
    "# Best Configuration Comparison (Sharpe Ratio vs Annual Return)\n",
    "best_data = data[data[\"quality\"] == \"best\"]\n",
    "scatter_plot(best_data, \"sharpe_ratio\", \"annual_return\", \"Best Configuration Comparison (GA vs PSO)\", \"Sharpe Ratio\", \"Annual Return\")\n",
    "\n",
    "print(\"✅ All statistical tests and visualizations completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611130b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
